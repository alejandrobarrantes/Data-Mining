#calcular_metricas(MC)
#calcular_metricas(MC2)
df <- data.frame(t(unlist(calcular_metricas(MC1))))
df2 <- data.frame(t(calcular_metricas(MC2)))
# Set the column names
names(df) <- c("precision_global", "error_global", "precision_positiva",
"precision_negativa", "falsos_positivos", "falsos_negativos",
"asertividad_positiva", "asertividad_negativa")
names(df2) <- c("precision_global", "error_global", "precision_positiva",
"precision_negativa", "falsos_positivos", "falsos_negativos",
"asertividad_positiva", "asertividad_negativa")
Salida <- rbind(df,df2)
#Salida
modelos<-list()
modelos[["Modelo1"]]<-modelo1
modelos[["Modelo2"]]<-modelo2
resultados <- data.frame(Modelo = character(),
Precisión_Global = numeric(),
Error_Global = numeric(),
Precisión_Positiva = numeric(),
Precisión_Negativa = numeric(),
stringsAsFactors = FALSE)
for (nombre_modelo in names(modelos)) {
modelo <- modelos[[nombre_modelo]]
prediccion <- predict(modelo, newdata = ttesting, type = "class")
matriz_confusion <- confusion.matrix(ttesting, prediccion)
print(matriz_confusion)
matriz_confusion<-general.indexes(mc=matriz_confusion)
if (!nombre_modelo %in% resultados$Modelo){
nueva_fila <- data.frame(Modelo = nombre_modelo,
Precisión_Global = matriz_confusion$overall.accuracy,
Error_Global = matriz_confusion$overall.error,
Precisión_Positiva = matriz_confusion$category.accuracy,
Precisión_Negativa = matriz_confusion$overall.error)
resultados <- rbind(resultados, nueva_fila)
}
}
resultados <- distinct(resultados, Modelo, .keep_all = TRUE)
resultados
print(matriz_confusion[1,1])
#calcular_metricas(MC)
#calcular_metricas(MC2)
df <- data.frame(t(unlist(calcular_metricas(MC1))))
df2 <- data.frame(t(calcular_metricas(MC2)))
# Set the column names
names(df) <- c("precision_global", "error_global", "precision_positiva",
"precision_negativa", "falsos_positivos", "falsos_negativos",
"asertividad_positiva", "asertividad_negativa")
names(df2) <- c("precision_global", "error_global", "precision_positiva",
"precision_negativa", "falsos_positivos", "falsos_negativos",
"asertividad_positiva", "asertividad_negativa")
Salida <- rbind(df,df2)
#Salida
modelos<-list()
modelos[["Modelo1"]]<-modelo1
modelos[["Modelo2"]]<-modelo2
resultados <- data.frame(Modelo = character(),
Precisión_Global = numeric(),
Error_Global = numeric(),
Precisión_Positiva = numeric(),
Precisión_Negativa = numeric(),
stringsAsFactors = FALSE)
for (nombre_modelo in names(modelos)) {
modelo <- modelos[[nombre_modelo]]
prediccion <- predict(modelo, newdata = ttesting, type = "class")
matriz_confusion <- confusion.matrix(ttesting, prediccion)
print(matriz_confusion[1,1])
matriz_confusion<-general.indexes(mc=matriz_confusion)
if (!nombre_modelo %in% resultados$Modelo){
nueva_fila <- data.frame(Modelo = nombre_modelo,
Precisión_Global = matriz_confusion$overall.accuracy,
Error_Global = matriz_confusion$overall.error,
Precisión_Positiva = matriz_confusion$category.accuracy,
Precisión_Negativa = matriz_confusion$overall.error)
resultados <- rbind(resultados, nueva_fila)
}
}
resultados <- distinct(resultados, Modelo, .keep_all = TRUE)
resultados
#calcular_metricas(MC)
#calcular_metricas(MC2)
df <- data.frame(t(unlist(calcular_metricas(MC1))))
df2 <- data.frame(t(calcular_metricas(MC2)))
# Set the column names
names(df) <- c("precision_global", "error_global", "precision_positiva",
"precision_negativa", "falsos_positivos", "falsos_negativos",
"asertividad_positiva", "asertividad_negativa")
names(df2) <- c("precision_global", "error_global", "precision_positiva",
"precision_negativa", "falsos_positivos", "falsos_negativos",
"asertividad_positiva", "asertividad_negativa")
Salida <- rbind(df,df2)
#Salida
modelos<-list()
modelos[["Modelo1"]]<-modelo1
modelos[["Modelo2"]]<-modelo2
resultados <- data.frame(Modelo = character(),
Precisión_Global = numeric(),
Error_Global = numeric(),
Falsos_Positivos = numeric(),
Falsos_Negativos = numeric(),
Precisión_Positiva = numeric(),
Precisión_Negativa = numeric(),
stringsAsFactors = FALSE)
for (nombre_modelo in names(modelos)) {
modelo <- modelos[[nombre_modelo]]
prediccion <- predict(modelo, newdata = ttesting, type = "class")
matriz_confusion <- confusion.matrix(ttesting, prediccion)
print(matriz_confusion[1,1])
indices.generales<-general.indexes(mc=matriz_confusion)
if (!nombre_modelo %in% resultados$Modelo){
nueva_fila <- data.frame(Modelo = nombre_modelo,
Precisión_Global = indices.generales$overall.accuracy,
Error_Global = indices.generales$overall.error,
Falsos_Positivos = matriz_confusion[1,2],
Falsos_Negativos = matriz_confusion[1,1],
Precisión_Positiva = indices.generales$category.accuracy,
Precisión_Negativa = indices.generales$overall.error)
resultados <- rbind(resultados, nueva_fila)
}
}
resultados <- distinct(resultados, Modelo, .keep_all = TRUE)
resultados
modelos<-list()
modelos[["Modelo1"]]<-modelo1
modelos[["Modelo2"]]<-modelo2
resultados <- data.frame(Modelo = character(),
Precisión_Global = numeric(),
Error_Global = numeric(),
Falsos_Positivos = numeric(),
Falsos_Negativos = numeric(),
Precisión_Positiva = numeric(),
Precisión_Negativa = numeric(),
stringsAsFactors = FALSE)
for (nombre_modelo in names(modelos)) {
modelo <- modelos[[nombre_modelo]]
prediccion <- predict(modelo, newdata = ttesting, type = "class")
matriz_confusion <- confusion.matrix(ttesting, prediccion)
print(matriz_confusion)
indices.generales<-general.indexes(mc=matriz_confusion)
if (!nombre_modelo %in% resultados$Modelo){
nueva_fila <- data.frame(Modelo = nombre_modelo,
Precisión_Global = indices.generales$overall.accuracy,
Error_Global = indices.generales$overall.error,
Falsos_Positivos = matriz_confusion[1,2],
Falsos_Negativos = matriz_confusion[1,1],
Precisión_Positiva = indices.generales$category.accuracy,
Precisión_Negativa = indices.generales$overall.error)
resultados <- rbind(resultados, nueva_fila)
}
}
resultados <- distinct(resultados, Modelo, .keep_all = TRUE)
resultados
modelos<-list()
modelos[["Modelo1"]]<-modelo1
modelos[["Modelo2"]]<-modelo2
resultados <- data.frame(Modelo = character(),
Precisión_Global = numeric(),
Error_Global = numeric(),
Falsos_Positivos = numeric(),
Falsos_Negativos = numeric(),
Precisión_Positiva = numeric(),
Precisión_Negativa = numeric(),
stringsAsFactors = FALSE)
for (nombre_modelo in names(modelos)) {
modelo <- modelos[[nombre_modelo]]
prediccion <- predict(modelo, newdata = ttesting, type = "class")
matriz_confusion <- confusion.matrix(ttesting, prediccion)
print(matriz_confusion)
indices.generales<-general.indexes(mc=matriz_confusion)
if (!nombre_modelo %in% resultados$Modelo){
nueva_fila <- data.frame(Modelo = nombre_modelo,
Precisión_Global = indices.generales$overall.accuracy,
Error_Global = indices.generales$overall.error,
Falsos_Positivos = matriz_confusion[1,2],
Falsos_Negativos = matriz_confusion[2,1],
Precisión_Positiva = indices.generales$category.accuracy,
Precisión_Negativa = indices.generales$overall.error)
resultados <- rbind(resultados, nueva_fila)
}
}
resultados <- distinct(resultados, Modelo, .keep_all = TRUE)
resultados
modelos<-list()
modelos[["Modelo1"]]<-modelo1
modelos[["Modelo2"]]<-modelo2
resultados <- data.frame(Modelo = character(),
Precisión_Global = numeric(),
Error_Global = numeric(),
Falsos_Positivos = numeric(),
Falsos_Negativos = numeric(),
Precisión_Positiva = numeric(),
Precisión_Negativa = numeric(),
Asertividad_Positiva = numeric(),
Asertividad_Negativa = numeric(),
stringsAsFactors = FALSE)
for (nombre_modelo in names(modelos)) {
modelo <- modelos[[nombre_modelo]]
prediccion <- predict(modelo, newdata = ttesting, type = "class")
matriz_confusion <- confusion.matrix(ttesting, prediccion)
print(matriz_confusion)
VN<-4
FN<-2
FP<-3
VP<-16
#("Precision global:")
P<-(VN+VP)/(VN+FP+FN+VP)
#("Error global: ")
E<-(1-P)
#("Precisión positiva:")
PP<- VP/(FN+VP)
#("Precisión negativa:")
PN<-VN/(VN+FP)
#("Asertividad positiva:")
AP <- VP/(FP+VP)
#("Asertividad negativa:")
AN <- VN/(VN+FN)
indices.generales<-general.indexes(mc=matriz_confusion)
if (!nombre_modelo %in% resultados$Modelo){
nueva_fila <- data.frame(Modelo = nombre_modelo,
Precisión_Global = indices.generales$overall.accuracy,
Error_Global = indices.generales$overall.error,
Precisión_Positiva = PP,
Precisión_Negativa = PN,
Falsos_Positivos = matriz_confusion[1,2],
Falsos_Negativos = matriz_confusion[2,1],
Asertividad_Positiva = AP,
Asertividad_Negativa = AN
)
resultados <- rbind(resultados, nueva_fila)
}
}
resultados <- distinct(resultados, Modelo, .keep_all = TRUE)
resultados
modelos<-list()
modelos[["Modelo1"]]<-modelo1
modelos[["Modelo2"]]<-modelo2
resultados <- data.frame(Modelo = character(),
Precisión_Global = numeric(),
Error_Global = numeric(),
Falsos_Positivos = numeric(),
Falsos_Negativos = numeric(),
Precisión_Positiva = numeric(),
Precisión_Negativa = numeric(),
Asertividad_Positiva = numeric(),
Asertividad_Negativa = numeric(),
stringsAsFactors = FALSE)
for (nombre_modelo in names(modelos)) {
modelo <- modelos[[nombre_modelo]]
prediccion <- predict(modelo, newdata = ttesting, type = "class")
matriz_confusion <- confusion.matrix(ttesting, prediccion)
print(matriz_confusion)
VN<-matriz_confusion[1,1]
FN<-matriz_confusion[1,2]
FP<-matriz_confusion[1,2]
VP<-matriz_confusion[2,2]
#("Precision global:")
P<-(VN+VP)/(VN+FP+FN+VP)
#("Error global: ")
E<-(1-P)
#("Precisión positiva:")
PP<- VP/(FN+VP)
#("Precisión negativa:")
PN<-VN/(VN+FP)
#("Asertividad positiva:")
AP <- VP/(FP+VP)
#("Asertividad negativa:")
AN <- VN/(VN+FN)
indices.generales<-general.indexes(mc=matriz_confusion)
if (!nombre_modelo %in% resultados$Modelo){
nueva_fila <- data.frame(Modelo = nombre_modelo,
Precisión_Global = indices.generales$overall.accuracy,
Error_Global = indices.generales$overall.error,
Precisión_Positiva = PP,
Precisión_Negativa = PN,
Falsos_Positivos = matriz_confusion[1,2],
Falsos_Negativos = matriz_confusion[2,1],
Asertividad_Positiva = AP,
Asertividad_Negativa = AN
)
resultados <- rbind(resultados, nueva_fila)
}
}
resultados <- distinct(resultados, Modelo, .keep_all = TRUE)
resultados
modelos<-list()
modelos[["Modelo1"]]<-modelo1
modelos[["Modelo2"]]<-modelo2
resultados <- data.frame(Modelo = character(),
Precisión_Global = numeric(),
Error_Global = numeric(),
Falsos_Positivos = numeric(),
Falsos_Negativos = numeric(),
Precisión_Positiva = numeric(),
Precisión_Negativa = numeric(),
Asertividad_Positiva = numeric(),
Asertividad_Negativa = numeric(),
stringsAsFactors = FALSE)
for (nombre_modelo in names(modelos)) {
modelo <- modelos[[nombre_modelo]]
prediccion <- predict(modelo, newdata = ttesting, type = "class")
matriz_confusion <- confusion.matrix(ttesting, prediccion)
print(matriz_confusion)
VN<-matriz_confusion[1,1]
FN<-matriz_confusion[2,1]
FP<-matriz_confusion[1,2]
VP<-matriz_confusion[2,2]
#("Precision global:")
P<-(VN+VP)/(VN+FP+FN+VP)
#("Error global: ")
E<-(1-P)
#("Precisión positiva:")
PP<- VP/(FN+VP)
#("Precisión negativa:")
PN<-VN/(VN+FP)
#("Asertividad positiva:")
AP <- VP/(FP+VP)
#("Asertividad negativa:")
AN <- VN/(VN+FN)
indices.generales<-general.indexes(mc=matriz_confusion)
if (!nombre_modelo %in% resultados$Modelo){
nueva_fila <- data.frame(Modelo = nombre_modelo,
Precisión_Global = indices.generales$overall.accuracy,
Error_Global = indices.generales$overall.error,
Precisión_Positiva = PP,
Precisión_Negativa = PN,
Falsos_Positivos = matriz_confusion[1,2],
Falsos_Negativos = matriz_confusion[2,1],
Asertividad_Positiva = AP,
Asertividad_Negativa = AN
)
resultados <- rbind(resultados, nueva_fila)
}
}
resultados <- distinct(resultados, Modelo, .keep_all = TRUE)
resultados
modelos<-list()
modelos[["Modelo1"]]<-modelo1
modelos[["Modelo2"]]<-modelo2
resultados <- data.frame(Modelo = character(),
Precisión_Global = numeric(),
Error_Global = numeric(),
Falsos_Positivos = numeric(),
Falsos_Negativos = numeric(),
Precisión_Positiva = numeric(),
Precisión_Negativa = numeric(),
Asertividad_Positiva = numeric(),
Asertividad_Negativa = numeric(),
stringsAsFactors = FALSE)
for (nombre_modelo in names(modelos)) {
modelo <- modelos[[nombre_modelo]]
prediccion <- predict(modelo, newdata = ttesting, type = "class")
matriz_confusion <- confusion.matrix(ttesting, prediccion)
print(matriz_confusion)
VN<-matriz_confusion[1,1]
FN<-matriz_confusion[2,1]
FP<-matriz_confusion[1,2]
VP<-matriz_confusion[2,2]
#("Precision global:")
P<-(VN+VP)/(VN+FP+FN+VP)
#("Error global: ")
E<-(1-P)
#("Precisión positiva:")
PP<- VP/(FN+VP)
#("Precisión negativa:")
PN<-VN/(VN+FP)
#("Asertividad positiva:")
AP <- VP/(FP+VP)
#("Asertividad negativa:")
AN <- VN/(VN+FN)
indices.generales<-general.indexes(mc=matriz_confusion)
if (!nombre_modelo %in% resultados$Modelo){
nueva_fila <- data.frame(Modelo = nombre_modelo,
Precisión_Global = indices.generales$overall.accuracy,
Error_Global = indices.generales$overall.error,
Precisión_Positiva = PP,
Precisión_Negativa = PN,
Falsos_Positivos = matriz_confusion[1,2],
Falsos_Negativos = matriz_confusion[2,1],
Asertividad_Positiva = AP,
Asertividad_Negativa = AN
)
resultados <- rbind(resultados, nueva_fila)
}
}
resultados <- distinct(resultados, Modelo, .keep_all = TRUE)
resultados
modelos<-list()
modelos[["Modelo1"]]<-modelo1
modelos[["Modelo2"]]<-modelo2
resultados <- data.frame(Modelo = character(),
Precisión_Global = numeric(),
Error_Global = numeric(),
Falsos_Positivos = numeric(),
Falsos_Negativos = numeric(),
Precisión_Positiva = numeric(),
Precisión_Negativa = numeric(),
Asertividad_Positiva = numeric(),
Asertividad_Negativa = numeric(),
stringsAsFactors = FALSE)
for (nombre_modelo in names(modelos)) {
modelo <- modelos[[nombre_modelo]]
prediccion <- predict(modelo, newdata = ttesting, type = "class")
matriz_confusion <- confusion.matrix(ttesting, prediccion)
VN<-matriz_confusion[1,1]
FN<-matriz_confusion[2,1]
FP<-matriz_confusion[1,2]
VP<-matriz_confusion[2,2]
#("Precision global:")
P<-(VN+VP)/(VN+FP+FN+VP)
#("Error global: ")
E<-(1-P)
#("Precisión positiva:")
PP<- VP/(FN+VP)
#("Precisión negativa:")
PN<-VN/(VN+FP)
#("Asertividad positiva:")
AP <- VP/(FP+VP)
#("Asertividad negativa:")
AN <- VN/(VN+FN)
indices.generales<-general.indexes(mc=matriz_confusion)
if (!nombre_modelo %in% resultados$Modelo){
nueva_fila <- data.frame(Modelo = nombre_modelo,
Precisión_Global = indices.generales$overall.accuracy,
Error_Global = indices.generales$overall.error,
Precisión_Positiva = PP,
Precisión_Negativa = PN,
Falsos_Positivos = matriz_confusion[1,2],
Falsos_Negativos = matriz_confusion[2,1],
Asertividad_Positiva = AP,
Asertividad_Negativa = AN
)
resultados <- rbind(resultados, nueva_fila)
}
}
resultados <- distinct(resultados, Modelo, .keep_all = TRUE)
resultados
modelos<-list()
modelos[["Modelo1"]]<-modelo1
modelos[["Modelo2"]]<-modelo2
resultados <- data.frame(Modelo = character(),
Precisión_Global = numeric(),
Error_Global = numeric(),
Falsos_Positivos = numeric(),
Falsos_Negativos = numeric(),
Precisión_Positiva = numeric(),
Precisión_Negativa = numeric(),
Asertividad_Positiva = numeric(),
Asertividad_Negativa = numeric(),
stringsAsFactors = FALSE)
for (nombre_modelo in names(modelos)) {
modelo <- modelos[[nombre_modelo]]
prediccion <- predict(modelo, newdata = ttesting, type = "class")
matriz_confusion <- confusion.matrix(ttesting, prediccion)
VN<-matriz_confusion[1,1]
FN<-matriz_confusion[2,1]
FP<-matriz_confusion[1,2]
VP<-matriz_confusion[2,2]
#("Precision global:")
P<-(VN+VP)/(VN+FP+FN+VP)
#("Error global: ")
E<-(1-P)
#("Precisión positiva:")
PP<- VP/(FN+VP)
#("Precisión negativa:")
PN<-VN/(VN+FP)
#("Asertividad positiva:")
AP <- VP/(FP+VP)
#("Asertividad negativa:")
AN <- VN/(VN+FN)
indices.generales<-general.indexes(mc=matriz_confusion)
if (!nombre_modelo %in% resultados$Modelo){
nueva_fila <- data.frame(Modelo = nombre_modelo,
Precisión_Global = indices.generales$overall.accuracy,
Error_Global = indices.generales$overall.error,
Precisión_Positiva = PP,
Precisión_Negativa = PN,
Falsos_Positivos = matriz_confusion[1,2],
Falsos_Negativos = matriz_confusion[2,1],
Asertividad_Positiva = AP,
Asertividad_Negativa = AN
)
resultados <- rbind(resultados, nueva_fila)
}
}
resultados <- distinct(resultados, Modelo, .keep_all = TRUE)
resultados
setwd("~/ALEJANDRO/1er Ciclo 2023/Mineria de Datos/Tarea 6/Datos Clase y Tareas")
Datos <- read.table("Cantidad-de-Suscripciones-y-Desinscripciones-de-SINPE-Móvil-por-Mes-_2015-2022_.csv", header=TRUE, sep=';',dec='.', stringsAsFactors = T)
Datos
Datos[1:4,1:4]
Datos[1:2,1:4]
Datos[1:2,1:2]
Datos[1:2]
View(Datos)
Datos <- read.table("Cantidad-de-Suscripciones-y-Desinscripciones-de-SINPE-Móvil-por-Mes-_2015-2022_.csv", header=TRUE, sep=',',dec=',', stringsAsFactors = T)
Datos[1:2]
Datos
View(Datos)
Datos["Mes"]
Datos[1,1]
Datos[1,1:4]
Datos[1,1:2]
Datos[1,1:1]
Datos[1:1,1:1]
Datos <- read.table("Cantidad-de-Suscripciones-y-Desinscripciones-de-SINPE-Móvil-por-Mes-_2015-2022_.csv", header=TRUE, sep=',',dec='.', stringsAsFactors = T)
Datos[1:1,1:1]
Datos <- read.table("Cantidad-de-Suscripciones-y-Desinscripciones-de-SINPE-Móvil-por-Mes-_2015-2022_.csv", header=TRUE, sep=';',dec=',', stringsAsFactors = T)
Datos[1:1,1:1]
Datos <- read.table("Cantidad-de-Suscripciones-y-Desinscripciones-de-SINPE-Móvil-por-Mes-_2015-2022_.csv", header=TRUE, sep=',',dec=',', stringsAsFactors = T)
Datos$Año..2.015...2.015...2.015...2.015...2.015...2.015...2.015...2.015...2.015...2.015...2.015...2.015...2.016...2.016...2.016...2.016...2.016...2.016...2.016...2.016...2.016...2.016...2.016...2.016...2.017...2.017...2.017...2.017...2.017...2.017...2.017...2.017...2.017...2.017...2.017...2.017...2.018...2.018...2.018...2.018...2.018...2.018...2.018...2.018...2.018...2.018...2.018...2.018...2.019...2.019...2.019...2.019...2.019...2.019...2.019...2.019...2.019...2.019...2.019...2.019...2.020...2.020...2.020...2.020...2.020...2.020...2.020...2.020...2.020...2.020...2.020...2.020...2.021...2.020...2.020...2.020...2.020...2.020...2.020...2.020...2.020...2.020...2.020...2.020...2.022...2.022...2.023...2.023...2.023...2.023...2.023...2.023...2.023...2.023...2.023...2.023...2.023...2.023...2.023.
Datos <- read.table("Cantidad-de-Suscripciones-y-Desinscripciones-de-SINPE-Móvil-por-Mes-_2015-2022_.csv", header=TRUE, sep=',',dec=',', stringsAsFactors = T)
Datos$Año..2.015...2.015...2.015...2.015...2.015...2.015...2.015...2.015...2.015...2.015...2.015...2.015...2.016...2.016...2.016...2.016...2.016...2.016...2.016...2.016...2.016...2.016...2.016...2.016...2.017...2.017...2.017...2.017...2.017...2.017...2.017...2.017...2.017...2.017...2.017...2.017...2.018...2.018...2.018...2.018...2.018...2.018...2.018...2.018...2.018...2.018...2.018...2.018...2.019...2.019...2.019...2.019...2.019...2.019...2.019...2.019...2.019...2.019...2.019...2.019...2.020...2.020...2.020...2.020...2.020...2.020...2.020...2.020...2.020...2.020...2.020...2.020...2.021...2.020...2.020...2.020...2.020...2.020...2.020...2.020...2.020...2.020...2.020...2.020...2.022...2.022...2.023...2.023...2.023...2.023...2.023...2.023...2.023...2.023...2.023...2.023...2.023...2.023...2.023.
